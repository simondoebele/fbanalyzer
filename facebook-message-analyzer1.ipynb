{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facebook Messages Parser and Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Current Features for each Chat: </b>\n",
    "\n",
    "<ul> \n",
    "<li> Create bar charts that contain the following information\n",
    "<ul> \n",
    "    <li> Number of words you have exchanged in a thread </li> \n",
    "    <li> Sentiment scores over time for sentences said </li> \n",
    "</ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pylab as plt #makes the plots\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import nltk\n",
    "import bisect\n",
    "import datetime\n",
    "import operator\n",
    "from lxml import html\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize\n",
    "import dateutil.parser as dateparser\n",
    "\n",
    "import copy\n",
    "import argparse\n",
    "\n",
    "#plot the graphs in terminal\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of conversations/html files you'd like to analyze\n",
    "NUMBER_TO_ANALYZE = 3\n",
    "\n",
    "# location of the html files\n",
    "DIRECTORY = 'messages/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used Python 3 and Ipython 6 for this task, but got a few errors and needed so long to make the code work that I decided to write some of it anew from scratch / borrow from other places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes for Message Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    message_parser\n",
    "    Enables parsing of messages from the Facebook HTML.\n",
    "    modified from https://github.com/mjmeli/facebook-chat-word-cloud/blob/master/facebook_wordcloud/message_parser.py\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\"\"\" Unique message parser exception \"\"\"\n",
    "class MessageParserException(Exception):\n",
    "    pass\n",
    "\n",
    "\"\"\" Represents a message in the message thread \"\"\"\n",
    "class Message:\n",
    "    # Each message has a sender, date, and a contents\n",
    "    def __init__(self, sender, date, contents):\n",
    "        self.sender = sender\n",
    "        if not isinstance(date, datetime.date):\n",
    "            self.date = dateparser.parse(date)\n",
    "        else:\n",
    "            self.date = date\n",
    "        self.contents = contents\n",
    "\n",
    "    # Comparison of two Messages relies on their date\n",
    "    def __lt__(self, other):\n",
    "        return self.date < other.date\n",
    "    def __gt__(self, other):\n",
    "        return self.date > other.date\n",
    "\n",
    "    # String representation of a message\n",
    "    def __repr__(self):\n",
    "        date_str = self.date.strftime(\"%a %b %d, %Y %I:%M %p\")\n",
    "        return self.sender + \" (\" + date_str + \"): \" + self.contents\n",
    "\n",
    "\"\"\" Represents a conversation thread. Thread = Conversation between a list of users since the beginning of time. \"\"\"\n",
    "class Thread:\n",
    "    # Each thread has a list of users and a list of messages\n",
    "    def __init__(self, users=None, messages=None):\n",
    "        if users is None:\n",
    "            self.users = set()\n",
    "        else:\n",
    "            self.users = set(users)\n",
    "        if messages is None:\n",
    "            self.messages = []\n",
    "        else:\n",
    "            for message in messages:\n",
    "                if not any(message.sender == user for user in self.users):\n",
    "                    raise ValueError\n",
    "            self.messages = sorted(messages, key=lambda x: x.date, reverse=False)\n",
    "\n",
    "    # Add a user to the conversation\n",
    "    def add_user(self, user):\n",
    "        self.users.add(user)\n",
    "\n",
    "    # Add a list of users to the conversation\n",
    "    def add_users(self, users):\n",
    "        self.users.update(users)\n",
    "\n",
    "    # Add a message to the conversation\n",
    "    def add_message(self, message):\n",
    "        if not any(message.sender == user for user in self.users):\n",
    "            raise ValueError\n",
    "        bisect.insort(self.messages, message)\n",
    "\n",
    "    # Return message contents\n",
    "    def get_messages_contents(self):\n",
    "        return [message.contents for message in self.messages]\n",
    "\n",
    "\"\"\" The message parser itself \"\"\"\n",
    "class MessageParser:\n",
    "    # HTML should be sent in as a string\n",
    "    def __init__(self, htmlstr):\n",
    "        if not isinstance(htmlstr, str):\n",
    "            raise ValueError\n",
    "        self.html = html.fromstring(htmlstr)\n",
    "\n",
    "    # Parse the HTML for a conversation thread\n",
    "    # Can send in either one user or a list of users\n",
    "    def parse_thread(self):\n",
    "        \n",
    "        # Create a new thread object\n",
    "        thread = Thread()\n",
    "\n",
    "        # Get all of the threads\n",
    "        potential_threads = self.html.xpath(\"//div[@class='thread']\")\n",
    "\n",
    "        # There may be multiple threads in the conversation.\n",
    "        threads_parsed = 0\n",
    "        messages_added = 0\n",
    "        messages_parsed = 0\n",
    "        \n",
    "        for potential_thread in potential_threads:\n",
    "            \n",
    "            # Track the number of threads_parsed\n",
    "            threads_parsed = threads_parsed + 1\n",
    "\n",
    "            # Get all of the message headers and message contents\n",
    "            message_headers = potential_thread.xpath(\"div[@class='message']\")\n",
    "            message_contents = potential_thread.xpath(\"p\")\n",
    "            print(\"Found \", len(message_headers),\" message(s) in thread \", threads_parsed)\n",
    "\n",
    "            # Extract the information from the messages\n",
    "            for i, header in enumerate(message_headers):\n",
    "                messages_parsed = messages_parsed + 1\n",
    "                try:\n",
    "                    sending_user = header.xpath(\"div/span[@class='user']/text()[1]\")[0]\n",
    "                    # Add user to the thread\n",
    "                    if not sending_user in thread.users:\n",
    "                        thread.add_user(sending_user)\n",
    "                    date = header.xpath(\"div/span[@class='meta']/text()[1]\")[0]\n",
    "                    contents = message_contents[i].xpath(\"text()\")[0]\n",
    "\n",
    "                    # Add a message to the thread\n",
    "                    thread.add_message(Message(sending_user, date, contents))\n",
    "\n",
    "                    messages_added = messages_added + 1\n",
    "                except (AttributeError, IndexError):\n",
    "                    # If the message is not a text message (i.e. picture), then\n",
    "                    # the call to text() will throw this exception. Do not\n",
    "                    # add this message as it contains no words.\n",
    "                    continue\n",
    "\n",
    "        # Print results\n",
    "        print(\"RESULTS: Parsed \", threads_parsed, \" thread(s) and \", messages_parsed, \" message(s) for \", messages_added, \" text message(s)\") \n",
    "\n",
    "        # Return the parsed thread\n",
    "        return thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of thread objects to be created\n",
    "thread_list = []\n",
    "\n",
    "# parse all files\n",
    "for i in range(NUMBER_TO_ANALYZE):\n",
    "    \n",
    "    print(\"Loading file...\")\n",
    "    filename = os.path.join(DIRECTORY, str(i) + '.html')\n",
    "    with open(filename, 'r') as f:\n",
    "        messages_file_data = f.read()\n",
    "\n",
    "    # Parse the HTML and extract messages (may take a long time)\n",
    "    print(\"Building HTML tree...\")\n",
    "    message_parser = MessageParser(messages_file_data)\n",
    "    print(\"Parsing messages...\")\n",
    "    thread = message_parser.parse_thread()\n",
    "    thread_list.append(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for features to analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function returns the word count of a thread\n",
    "def get_word_count(thread):\n",
    "    print(\"Analyzing messages for word frequencies...\")\n",
    "    messages = thread.get_messages_contents() # list of message strings\n",
    "    s = \" \"\n",
    "    conversation = s.join(messages) # joins the list of strings to one continuous string of conversation\n",
    "    tokens = word_tokenize(conversation) # split string into tokens\n",
    "    text = nltk.Text(tokens) \n",
    "    return len(text)\n",
    "    \n",
    "# Returns a dictionary that associates users and their respective word count with you\n",
    "def word_count_per_user(thread_list):\n",
    "    dic = {}\n",
    "    for thread in thread_list:\n",
    "        user_s = \", \".join(thread.users)\n",
    "        dic[user_s] = get_word_count(thread)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return a(!) mean sentiment score, based on SentimentIntensityAnalyzer: \n",
    "# compound is an overall positive or negative score.\n",
    "def mean_sid(messages, qualify='compound'):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    return np.mean([sid.polarity_scores(sentence)[qualify] for sentence in messages])\n",
    "\n",
    "# creates the 4 different sentiment scores per sentence (neu = neutral, neg = negative, pos = positive, compound = overall)\n",
    "def sentiment_over_time(messages):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    neg = np.array([sid.polarity_scores(sentence)['neg'] for sentence in messages])\n",
    "    pos = np.array([sid.polarity_scores(sentence)['pos'] for sentence in messages])\n",
    "    neu = np.array([sid.polarity_scores(sentence)['neu'] for sentence in messages])\n",
    "    compound = np.array([sid.polarity_scores(sentence)['compound'] for sentence in messages])\n",
    "    return neg, pos, neu, compound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Analysis & Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = word_count_per_user(thread_list)\n",
    "\n",
    "# sorted_word_counts: a list of tuples sorted by the second element in each tuple, \n",
    "# i.e. the value of the dictionary. dict(sorted_x) == x.\n",
    "sorted_word_counts = sorted(word_counts.items(), key=operator.itemgetter(1))\n",
    "# sort from highest to lowest (i.e. reverse previous)\n",
    "sorted_word_counts.sort(key=lambda x: x[1], reverse=True) \n",
    "\n",
    "# unpack a list of pairs into two tuples\n",
    "users, word_count = zip(*sorted_word_counts)\n",
    "X = np.arange(len(users))\n",
    "\n",
    "plt.bar(X, word_count, align='center', width=0.5)\n",
    "plt.xticks(X, users, rotation = 90)\n",
    "plt.title('Word Counts with User')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis - Timeseries of sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a thread\n",
    "THREAD_TO_ANALYZE = 2\n",
    "thread = thread_list[THREAD_TO_ANALYZE]\n",
    "\n",
    "# list of messages\n",
    "messages = thread.get_messages_contents()\n",
    "# mean sentiment score with your chosen thread\n",
    "mean_sid(messages)\n",
    "\n",
    "np.random.randn(20,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sentiment scores over time for your chosen thread\n",
    "neg, pos, neu, compound = sentiment_over_time(messages)\n",
    "\n",
    "data = {'neg' : pd.Series(neg),'pos' : pd.Series(pos), 'neu' : pd.Series(neu), 'compound' : pd.Series(compound)}\n",
    "df = pd.DataFrame(data, columns = ['neg', 'pos', 'neu', 'compound'])\n",
    "\n",
    "df.plot(kind='line')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
